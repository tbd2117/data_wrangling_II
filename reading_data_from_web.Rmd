---
title: "Reading_data_from_the_web"
output: github_document
date: 10/14/2020
---

```{r setup}
library(tidyverse)
library(rvest)
library(httr)
```

### Read data from url

```{r}
url = "http://samhda.s3-us-gov-west-1.amazonaws.com/s3fs-public/field-uploads/2k15StateFiles/NSDUHsaeShortTermCHG2015.htm"
drug_use_html = read_html(url)

drug_use_html
```

### getting all tables from url

```{r}
drug_use_html %>%
  html_nodes(css = "table")
```

## just the first one

```{r}
table_marj = 
  drug_use_html %>% 
  html_nodes(css = "table") %>% 
  first() %>%
  html_table() %>% 
  slice(-1) %>%  #this is to remove the firs row that contains text
  as_tibble() # make it nicer
```

## LEARNING ASSESSMENT

```{r}
table_cost_living_nyc =
  read_html("https://www.bestplaces.net/cost_of_living/city/new_york/new_york") %>% 
  html_nodes(css = "table") %>% 
  .[[1]]%>% 
  html_table(header=TRUE)
```

### CSS selectors

IMDB url on starwars movies
```{r}
swm_html = 
  read_html("https://www.imdb.com/list/ls070150896/")
```

For each element, I’ll use the CSS selector in html_nodes() to extract the relevant HTML code, and convert it to text. Then I can combine these into a data frame.

```{r}
title_vec = 
  swm_html %>%
  html_nodes(".lister-item-header a") %>%
  html_text()

gross_rev_vec = 
  swm_html %>%
  html_nodes(".text-small:nth-child(7) span:nth-child(5)") %>%
  html_text()

runtime_vec = 
  swm_html %>%
  html_nodes(".runtime") %>%
  html_text()

swm_df = 
  tibble(
    title = title_vec,
    rev = gross_rev_vec,
    runtime = runtime_vec)
```

### Using an API

```{r}
nyc_water = 
  GET("https://data.cityofnewyork.us/resource/ia2d-e54m.csv") %>% 
  content("parsed")

brfss_smart2010 = 
  GET("https://chronicdata.cdc.gov/resource/acme-vg9e.csv",
      query = list("$limit" = 5000)) %>% 
  content("parsed")

poke = 
  GET("http://pokeapi.co/api/v2/pokemon/1") %>%
  content()

poke$name
```
To build a Pokemon dataset for analysis, you’d need to distill the data returned from the API into a useful format; iterate across all pokemon; and combine the results.

For both of the API examples we saw today, it wouldn’t be terrible to just download the CSV, document where it came from carefully, and move on. APIs are more helpful when the full dataset is complex and you only need pieces, or when the data are updated regularly.


